#  Mini-Projet MLOps - Classification Iris

Pipeline MLOps complet pour la classification de fleurs Iris (setosa, versicolor, virginica) en utilisant les bonnes pratiques industrielles.

##  Objectif du projet

Mettre en place un pipeline MLOps complet pour un modÃ¨le de Machine Learning, depuis les donnÃ©es jusqu'au dÃ©ploiement, en utilisant les bonnes pratiques industrielles.

Le modÃ¨le prÃ©dit la classe de la fleur Iris Ã  partir de ses caractÃ©ristiques (sepal_length, sepal_width, petal_length, petal_width).

##  Technologies utilisÃ©es

- **Python 3.11** - Langage de programmation
- **Scikit-learn** - ModÃ¨les ML (Logistic Regression, SVM)
- **MLflow** - Tracking des expÃ©riences et versioning des modÃ¨les
- **Optuna** - Optimisation automatique des hyperparamÃ¨tres
- **FastAPI** - API REST pour les prÃ©dictions
- **Docker & Docker Compose** - Conteneurisation et orchestration
- **Git** - Versioning du code
- **DVC + MinIO** - Versioning des donnÃ©es

##  Structure du projet

```
mini-mlops-iris/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py              # API FastAPI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_baseline.py    # EntraÃ®nement baseline
â”‚   â”‚   â””â”€â”€ train_optuna.py      # Optimisation avec Optuna
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ load_data.py         # Chargement des donnÃ©es
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # DonnÃ©es brutes (versionnÃ©es avec DVC)
â”‚   â””â”€â”€ processed/               # DonnÃ©es traitÃ©es
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.joblib        # Meilleur modÃ¨le sauvegardÃ©
â”œâ”€â”€ mlruns/                       # Runs MLflow
â”œâ”€â”€ mlflow.db                     # Base de donnÃ©es MLflow
â”œâ”€â”€ Dockerfile                    # Image Docker pour l'API
â”œâ”€â”€ Dockerfile.mlflow             # Image Docker pour MLflow
â”œâ”€â”€ docker-compose.yml            # Orchestration API + MLflow
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python (dÃ©veloppement)
â”œâ”€â”€ requirements-docker.txt       # DÃ©pendances Python (Docker - minimal)
â”œâ”€â”€ render.yaml                   # Configuration Render.com
â”œâ”€â”€ railway.json                  # Configuration Railway.app
â”œâ”€â”€ Procfile                      # Configuration Heroku
â”œâ”€â”€ runtime.txt                   # Version Python pour Heroku
â”œâ”€â”€ README.md                     # Documentation principale
â”œâ”€â”€ VERIFICATION.md               # Guide de vÃ©rification
â””â”€â”€ QUICK_START.md                # Guide de dÃ©marrage rapide
```

##  Architecture du pipeline MLOps

### Vue d'ensemble du pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE MLOPS COMPLET                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DONNÃ‰ES  â”‚  Iris Dataset (4 features: sepal, petal)
â”‚   (DVC)      â”‚  â””â”€> Versioning avec DVC + MinIO
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PRÃ‰PARATIONâ”‚  Train/Test Split (80/20)
â”‚   DONNÃ‰ES    â”‚  â””â”€> StandardScaler
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ENTRAÃNEMENTâ”‚ Baseline: Logistic Regression / SVM
â”‚   BASELINE   â”‚  â””â”€> Sauvegarde: models/best_model.joblib
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MLFLOW    â”‚  Tracking: paramÃ¨tres, mÃ©triques, modÃ¨les
â”‚   TRACKING   â”‚  â””â”€> UI: http://localhost:5000
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. OPTUNA    â”‚  Optimisation hyperparamÃ¨tres (C, kernel)
â”‚ OPTIMIZATION â”‚  â””â”€> SÃ©lection meilleur modÃ¨le
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. FASTAPI   â”‚  API REST de prÃ©diction
â”‚    SERVICE   â”‚  â””â”€> Endpoints: /health, /predict
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. DOCKER    â”‚  Conteneurisation
â”‚   COMPOSE    â”‚  â””â”€> API + MLflow orchestrÃ©s
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. CLOUD     â”‚  DÃ©ploiement (Render, Railway, Azure)
â”‚  DEPLOYMENT  â”‚  â””â”€> Production ready
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture technique dÃ©taillÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER COMPOSE STACK                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   iris-api       â”‚         â”‚   mlflow         â”‚          â”‚
â”‚  â”‚   (FastAPI)      â”‚         â”‚   (Tracking UI)  â”‚          â”‚
â”‚  â”‚                  â”‚         â”‚                  â”‚          â”‚
â”‚  â”‚  Port: 8000      â”‚         â”‚  Port: 5000      â”‚          â”‚
â”‚  â”‚  /health         â”‚         â”‚  /mlflow         â”‚          â”‚
â”‚  â”‚  /predict        â”‚         â”‚  /experiments    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                              â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                    â”‚                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚         â”‚  mlops-network      â”‚                               â”‚
â”‚         â”‚  (bridge network)   â”‚                               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                               â”‚
â”‚  Volumes partagÃ©s:                                            â”‚
â”‚  - ./models â†’ /app/models (read-only)                        â”‚
â”‚  - ./mlruns â†’ /mlflow/mlruns                                 â”‚
â”‚  - ./mlflow.db â†’ /mlflow/mlflow.db                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

##  Installation et utilisation

### PrÃ©requis

- Python 3.11+
- Docker & Docker Compose
- Git
- DVC (optionnel, pour le versioning des donnÃ©es)

### 1. Cloner le projet

```bash
git clone <repository-url>
cd mini-mlops-iris
```

### 2. CrÃ©er l'environnement virtuel

```bash
python -m venv .venv
source .venv/bin/activate  # Sur Windows: .venv\Scripts\activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

Pour l'entraÃ®nement complet (avec MLflow et Optuna) :
```bash
pip install mlflow optuna dvc
```

### 4. Charger les donnÃ©es

```bash
python src/utils/load_data.py
```

### 5. EntraÃ®ner le modÃ¨le baseline

```bash
# Logistic Regression
python src/training/train_baseline.py --model logreg --C 1.0

# SVM
python src/training/train_baseline.py --model svm --C 1.0 --kernel rbf
```

### 6. Optimiser avec Optuna

```bash
python src/training/train_optuna.py
```

### 7. Lancer MLflow UI

```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

AccÃ©der Ã  l'interface : http://localhost:5000

### 8. Lancer l'API localement

```bash
uvicorn api.main:app --reload
```

AccÃ©der Ã  l'API : http://localhost:8000
- Documentation Swagger : http://localhost:8000/docs
- Health check : http://localhost:8000/health

### 9. Tester l'API

```bash
# Health check
curl http://localhost:8000/health

# PrÃ©diction
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'
```

##  DÃ©ploiement avec Docker

### Build et lancement avec Docker Compose

```bash
# Construire et lancer le service
docker compose up --build

# Lancer en arriÃ¨re-plan
docker compose up -d

# Voir les logs
docker compose logs -f

# ArrÃªter les services
docker compose down
```

### Build manuel de l'image Docker

```bash
# Build l'image
docker build -t iris-api:1.0 .

# Lancer le conteneur
docker run --rm -p 8000:8000 iris-api:1.0
```

### Services disponibles avec Docker Compose

Lorsque vous lancez `docker compose up`, deux services sont disponibles :

- **API FastAPI** : http://localhost:8000
  - Documentation Swagger : http://localhost:8000/docs
  - Health check : http://localhost:8000/health
  - Endpoint de prÃ©diction : http://localhost:8000/predict

- **MLflow UI** : http://localhost:5000
  - Interface de tracking des expÃ©riences
  - Visualisation des mÃ©triques et paramÃ¨tres
  - Comparaison des modÃ¨les

## ğŸ“Š Endpoints de l'API

### `GET /health`

VÃ©rifie l'Ã©tat de l'API.

**RÃ©ponse :**
```json
{
  "status": "ok"
}
```

### `POST /predict`

Effectue une prÃ©diction de classe Iris.

**Body (JSON) :**
```json
{
  "sepal_length": 5.1,
  "sepal_width": 3.5,
  "petal_length": 1.4,
  "petal_width": 0.2
}
```

**RÃ©ponse :**
```json
{
  "prediction": 0,
  "class_name": "setosa"
}
```

**Classes :**
- `0` : setosa
- `1` : versicolor
- `2` : virginica

##  Commandes utiles

### MLflow

```bash
# Lancer MLflow UI
mlflow ui --backend-store-uri sqlite:///mlflow.db

# Lister les expÃ©riences
mlflow experiments list
```

### Docker

```bash
# Voir les conteneurs actifs
docker ps

# Build l'image
docker build -t iris-api:1.0 .

# Lancer le conteneur
docker run --rm -p 8000:8000 iris-api:1.0

# Voir les logs
docker compose logs -f
```

### Git & DVC

```bash
# Versioning des donnÃ©es avec DVC
dvc add data/raw/iris.csv
dvc push  # Push vers MinIO (si configurÃ©)
```

## ğŸ“ PrÃ©sentation du projet

> "J'ai rÃ©alisÃ© un mini-projet MLOps complet incluant la gestion des donnÃ©es avec DVC, le suivi des expÃ©riences avec MLflow, l'optimisation avec Optuna et le dÃ©ploiement d'un modÃ¨le via une API FastAPI, le tout versionnÃ© avec Git et conteneurisÃ© avec Docker."

##  FonctionnalitÃ©s implÃ©mentÃ©es

### Core MLOps
- Structure MLOps complÃ¨te et organisÃ©e
- Versioning des donnÃ©es (DVC + MinIO)
- EntraÃ®nement de modÃ¨les baseline (Logistic Regression, SVM)
-  Tracking des expÃ©riences (MLflow)
-  Optimisation des hyperparamÃ¨tres (Optuna)

### DÃ©ploiement
-  API REST de prÃ©diction (FastAPI)
-  Conteneurisation (Docker)
- Orchestration (Docker Compose avec API + MLflow)
-  Configuration cloud (Render, Railway, Heroku)

### Documentation
-  README complet avec architecture
-  Guide de vÃ©rification (VERIFICATION.md)
-  Guide de dÃ©marrage rapide (QUICK_START.md)
-  SchÃ©mas du pipeline MLOps

##  Troubleshooting

### Le modÃ¨le n'est pas trouvÃ©

Assurez-vous d'avoir entraÃ®nÃ© le modÃ¨le avant de lancer l'API :
```bash
python src/training/train_baseline.py --model logreg
```

### Port dÃ©jÃ  utilisÃ©

Si le port 8000 ou 5000 est dÃ©jÃ  utilisÃ©, modifiez les ports dans `docker-compose.yml`.

### Erreur Docker

VÃ©rifiez que Docker est bien lancÃ© :
```bash
docker ps
```

##  DÃ©ploiement Cloud (Bonus)

Le projet inclut des configurations pour le dÃ©ploiement sur diffÃ©rentes plateformes cloud.

### Render.com

1. CrÃ©er un compte sur [Render](https://render.com)
2. Connecter votre repository GitHub
3. Render dÃ©tectera automatiquement `render.yaml`
4. Le service sera dÃ©ployÃ© automatiquement

**Fichier de configuration :** `render.yaml`

### Railway.app

1. CrÃ©er un compte sur [Railway](https://railway.app)
2. CrÃ©er un nouveau projet depuis GitHub
3. Railway utilisera `railway.json` pour la configuration
4. Le dÃ©ploiement se fait automatiquement

**Fichier de configuration :** `railway.json`

### Heroku

1. Installer [Heroku CLI](https://devcenter.heroku.com/articles/heroku-cli)
2. Se connecter : `heroku login`
3. CrÃ©er une app : `heroku create iris-api`
4. DÃ©ployer : `git push heroku main`

**Fichiers de configuration :** `Procfile`, `runtime.txt`

### Azure Container Instances

```bash
# Build et push vers Azure Container Registry
az acr build --registry <registry-name> --image iris-api:latest .

# DÃ©ployer
az container create \
  --resource-group <resource-group> \
  --name iris-api \
  --image <registry-name>.azurecr.io/iris-api:latest \
  --dns-name-label iris-api \
  --ports 8000
```

### Variables d'environnement Cloud

Pour tous les dÃ©ploiements cloud, assurez-vous de :
- Configurer le port via la variable `PORT` (gÃ©nÃ©ralement fournie automatiquement)
- Inclure le modÃ¨le `best_model.joblib` dans l'image Docker
- Configurer les volumes persistants si nÃ©cessaire (pour MLflow)

##  Ressources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Optuna Documentation](https://optuna.org/)
- [Docker Documentation](https://docs.docker.com/)
- [Render Documentation](https://render.com/docs)
- [Railway Documentation](https://docs.railway.app/)

##  Licence

Ce projet est un projet Ã©ducatif.

---

**Auteur** : Mini-Projet MLOps  
**Date** : 2024
